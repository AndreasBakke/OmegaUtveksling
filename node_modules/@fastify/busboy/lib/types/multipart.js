'use strict'

// TODO:
//  * support 1 nested multipart level
//    (see second multipart example here:
//     http://www.w3.org/TR/html401/interact/forms.html#didx-multipartform-data)
//  * support limits.fieldNameSize
//     -- this will require modifications to utils.parseParams

const ReadableStream = require('stream').Readable
const inherits = require('util').inherits

const Dicer = require('../../deps/dicer/lib/Dicer')

const parseParams = require('../utils/parseParams')
const decodeText = require('../utils/decodeText')
const basename = require('../utils/basename')
const getLimit = require('../utils/getLimit')

const RE_BOUNDARY = /^boundary$/i
const RE_FIELD = /^form-data$/i
const RE_CHARSET = /^charset$/i
const RE_FILENAME = /^filename$/i
const RE_NAME = /^name$/i

Multipart.detect = /^multipart\/form-data/i
function Multipart (boy, cfg) ***REMOVED***
  let i
  let len
  const self = this
  let boundary
  const limits = cfg.limits
  const isPartAFile = cfg.isPartAFile || ((fieldName, contentType, fileName) => (contentType === 'application/octet-stream' || fileName !== undefined))
  const parsedConType = cfg.parsedConType || []
  const defCharset = cfg.defCharset || 'utf8'
  const preservePath = cfg.preservePath
  const fileOpts = ***REMOVED*** highWaterMark: cfg.fileHwm }

  for (i = 0, len = parsedConType.length; i < len; ++i) ***REMOVED***
    if (Array.isArray(parsedConType[i]) &&
      RE_BOUNDARY.test(parsedConType[i][0])) ***REMOVED***
      boundary = parsedConType[i][1]
      break
  ***REMOVED***
***REMOVED***

  function checkFinished () ***REMOVED***
    if (nends === 0 && finished && !boy._done) ***REMOVED***
      finished = false
      process.nextTick(function () ***REMOVED***
        boy._done = true
        boy.emit('finish')
    ***REMOVED***)
  ***REMOVED***
***REMOVED***

  if (typeof boundary !== 'string') ***REMOVED*** throw new Error('Multipart: Boundary not found') }

  const fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)
  const fileSizeLimit = getLimit(limits, 'fileSize', Infinity)
  const filesLimit = getLimit(limits, 'files', Infinity)
  const fieldsLimit = getLimit(limits, 'fields', Infinity)
  const partsLimit = getLimit(limits, 'parts', Infinity)
  const headerPairsLimit = getLimit(limits, 'headerPairs', 2000)
  const headerSizeLimit = getLimit(limits, 'headerSize', 80 * 1024)

  let nfiles = 0
  let nfields = 0
  let nends = 0
  let curFile
  let curField
  let finished = false

  this._needDrain = false
  this._pause = false
  this._cb = undefined
  this._nparts = 0
  this._boy = boy

  const parserCfg = ***REMOVED***
    boundary,
    maxHeaderPairs: headerPairsLimit,
    maxHeaderSize: headerSizeLimit,
    partHwm: fileOpts.highWaterMark,
    highWaterMark: cfg.highWaterMark
***REMOVED***

  this.parser = new Dicer(parserCfg)
  this.parser.on('drain', function () ***REMOVED***
    self._needDrain = false
    if (self._cb && !self._pause) ***REMOVED***
      const cb = self._cb
      self._cb = undefined
      cb()
  ***REMOVED***
***REMOVED***).on('part', function onPart (part) ***REMOVED***
    if (++self._nparts > partsLimit) ***REMOVED***
      self.parser.removeListener('part', onPart)
      self.parser.on('part', skipPart)
      boy.hitPartsLimit = true
      boy.emit('partsLimit')
      return skipPart(part)
  ***REMOVED***

    // hack because streams2 _always_ doesn't emit 'end' until nextTick, so let
    // us emit 'end' early since we know the part has ended if we are already
    // seeing the next part
    if (curField) ***REMOVED***
      const field = curField
      field.emit('end')
      field.removeAllListeners('end')
  ***REMOVED***

    part.on('header', function (header) ***REMOVED***
      let contype
      let fieldname
      let parsed
      let charset
      let encoding
      let filename
      let nsize = 0

      if (header['content-type']) ***REMOVED***
        parsed = parseParams(header['content-type'][0])
        if (parsed[0]) ***REMOVED***
          contype = parsed[0].toLowerCase()
          for (i = 0, len = parsed.length; i < len; ++i) ***REMOVED***
            if (RE_CHARSET.test(parsed[i][0])) ***REMOVED***
              charset = parsed[i][1].toLowerCase()
              break
          ***REMOVED***
        ***REMOVED***
      ***REMOVED***
    ***REMOVED***

      if (contype === undefined) ***REMOVED*** contype = 'text/plain' }
      if (charset === undefined) ***REMOVED*** charset = defCharset }

      if (header['content-disposition']) ***REMOVED***
        parsed = parseParams(header['content-disposition'][0])
        if (!RE_FIELD.test(parsed[0])) ***REMOVED*** return skipPart(part) }
        for (i = 0, len = parsed.length; i < len; ++i) ***REMOVED***
          if (RE_NAME.test(parsed[i][0])) ***REMOVED***
            fieldname = parsed[i][1]
        ***REMOVED*** else if (RE_FILENAME.test(parsed[i][0])) ***REMOVED***
            filename = parsed[i][1]
            if (!preservePath) ***REMOVED*** filename = basename(filename) }
        ***REMOVED***
      ***REMOVED***
    ***REMOVED*** else ***REMOVED*** return skipPart(part) }

      if (header['content-transfer-encoding']) ***REMOVED*** encoding = header['content-transfer-encoding'][0].toLowerCase() } else ***REMOVED*** encoding = '7bit' }

      let onData,
        onEnd

      if (isPartAFile(fieldname, contype, filename)) ***REMOVED***
        // file/binary field
        if (nfiles === filesLimit) ***REMOVED***
          if (!boy.hitFilesLimit) ***REMOVED***
            boy.hitFilesLimit = true
            boy.emit('filesLimit')
        ***REMOVED***
          return skipPart(part)
      ***REMOVED***

        ++nfiles

        if (!boy._events.file) ***REMOVED***
          self.parser._ignore()
          return
      ***REMOVED***

        ++nends
        const file = new FileStream(fileOpts)
        curFile = file
        file.on('end', function () ***REMOVED***
          --nends
          self._pause = false
          checkFinished()
          if (self._cb && !self._needDrain) ***REMOVED***
            const cb = self._cb
            self._cb = undefined
            cb()
        ***REMOVED***
      ***REMOVED***)
        file._read = function (n) ***REMOVED***
          if (!self._pause) ***REMOVED*** return }
          self._pause = false
          if (self._cb && !self._needDrain) ***REMOVED***
            const cb = self._cb
            self._cb = undefined
            cb()
        ***REMOVED***
      ***REMOVED***
        boy.emit('file', fieldname, file, filename, encoding, contype)

        onData = function (data) ***REMOVED***
          if ((nsize += data.length) > fileSizeLimit) ***REMOVED***
            const extralen = fileSizeLimit - nsize + data.length
            if (extralen > 0) ***REMOVED*** file.push(data.slice(0, extralen)) }
            file.truncated = true
            file.bytesRead = fileSizeLimit
            part.removeAllListeners('data')
            file.emit('limit')
            return
        ***REMOVED*** else if (!file.push(data)) ***REMOVED*** self._pause = true }

          file.bytesRead = nsize
      ***REMOVED***

        onEnd = function () ***REMOVED***
          curFile = undefined
          file.push(null)
      ***REMOVED***
    ***REMOVED*** else ***REMOVED***
        // non-file field
        if (nfields === fieldsLimit) ***REMOVED***
          if (!boy.hitFieldsLimit) ***REMOVED***
            boy.hitFieldsLimit = true
            boy.emit('fieldsLimit')
        ***REMOVED***
          return skipPart(part)
      ***REMOVED***

        ++nfields
        ++nends
        let buffer = ''
        let truncated = false
        curField = part

        onData = function (data) ***REMOVED***
          if ((nsize += data.length) > fieldSizeLimit) ***REMOVED***
            const extralen = (fieldSizeLimit - (nsize - data.length))
            buffer += data.toString('binary', 0, extralen)
            truncated = true
            part.removeAllListeners('data')
        ***REMOVED*** else ***REMOVED*** buffer += data.toString('binary') }
      ***REMOVED***

        onEnd = function () ***REMOVED***
          curField = undefined
          if (buffer.length) ***REMOVED*** buffer = decodeText(buffer, 'binary', charset) }
          boy.emit('field', fieldname, buffer, false, truncated, encoding, contype)
          --nends
          checkFinished()
      ***REMOVED***
    ***REMOVED***

      /* As of node@2efe4ab761666 (v0.10.29+/v0.11.14+), busboy had become
         broken. Streams2/streams3 is a huge black box of confusion, but
         somehow overriding the sync state seems to fix things again (and still
         seems to work for previous node versions).
      */
      part._readableState.sync = false

      part.on('data', onData)
      part.on('end', onEnd)
  ***REMOVED***).on('error', function (err) ***REMOVED***
      if (curFile) ***REMOVED*** curFile.emit('error', err) }
  ***REMOVED***)
***REMOVED***).on('error', function (err) ***REMOVED***
    boy.emit('error', err)
***REMOVED***).on('finish', function () ***REMOVED***
    finished = true
    checkFinished()
***REMOVED***)
}

Multipart.prototype.write = function (chunk, cb) ***REMOVED***
  let r
  if ((r = this.parser.write(chunk)) && !this._pause) ***REMOVED*** cb() } else ***REMOVED***
    this._needDrain = !r
    this._cb = cb
***REMOVED***
}

Multipart.prototype.end = function () ***REMOVED***
  const self = this
  if (this._nparts === 0 && !self._boy._done) ***REMOVED***
    process.nextTick(function () ***REMOVED***
      self._boy._done = true
      self._boy.emit('finish')
  ***REMOVED***)
***REMOVED*** else if (this.parser.writable) ***REMOVED*** this.parser.end() }
}

function skipPart (part) ***REMOVED***
  part.resume()
}

function FileStream (opts) ***REMOVED***
  ReadableStream.call(this, opts)

  this.bytesRead = 0

  this.truncated = false
}
inherits(FileStream, ReadableStream)

FileStream.prototype._read = function (n) ***REMOVED*** }

module.exports = Multipart
