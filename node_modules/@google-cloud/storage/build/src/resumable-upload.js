"use strict";
// Copyright 2022 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
Object.defineProperty(exports, "__esModule", ***REMOVED*** value: true });
exports.createURI = exports.upload = exports.Upload = exports.PROTOCOL_REGEX = void 0;
const abort_controller_1 = require("abort-controller");
const crypto_1 = require("crypto");
const extend = require("extend");
const gaxios = require("gaxios");
const google_auth_library_1 = require("google-auth-library");
const stream_1 = require("stream");
const retry = require("async-retry");
const uuid = require("uuid");
const NOT_FOUND_STATUS_CODE = 404;
const RESUMABLE_INCOMPLETE_STATUS_CODE = 308;
const DEFAULT_API_ENDPOINT_REGEX = /.*\.googleapis\.com/;
const packageJson = require('../../package.json');
exports.PROTOCOL_REGEX = /^(\w*):\/\//;
class Upload extends stream_1.Writable ***REMOVED***
    constructor(cfg) ***REMOVED***
        super();
        this.numBytesWritten = 0;
        this.numRetries = 0;
        this.currentInvocationId = ***REMOVED***
            chunk: uuid.v4(),
            uri: uuid.v4(),
            offset: uuid.v4(),
      ***REMOVED***;
        this.upstreamChunkBuffer = Buffer.alloc(0);
        this.chunkBufferEncoding = undefined;
        this.numChunksReadInRequest = 0;
        /**
         * A chunk used for caching the most recent upload chunk.
         * We should not assume that the server received all bytes sent in the request.
         *  - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload
         */
        this.lastChunkSent = Buffer.alloc(0);
        this.upstreamEnded = false;
        cfg = cfg || ***REMOVED***};
        if (!cfg.bucket || !cfg.file) ***REMOVED***
            throw new Error('A bucket and file name are required');
      ***REMOVED***
        cfg.authConfig = cfg.authConfig || ***REMOVED***};
        cfg.authConfig.scopes = [
            'https://www.googleapis.com/auth/devstorage.full_control',
        ];
        this.authClient = cfg.authClient || new google_auth_library_1.GoogleAuth(cfg.authConfig);
        this.apiEndpoint = 'https://storage.googleapis.com';
        if (cfg.apiEndpoint) ***REMOVED***
            this.apiEndpoint = this.sanitizeEndpoint(cfg.apiEndpoint);
            if (!DEFAULT_API_ENDPOINT_REGEX.test(cfg.apiEndpoint)) ***REMOVED***
                this.authClient = gaxios;
          ***REMOVED***
      ***REMOVED***
        this.baseURI = `$***REMOVED***this.apiEndpoint}/upload/storage/v1/b`;
        this.bucket = cfg.bucket;
        const cacheKeyElements = [cfg.bucket, cfg.file];
        if (typeof cfg.generation === 'number') ***REMOVED***
            cacheKeyElements.push(`$***REMOVED***cfg.generation}`);
      ***REMOVED***
        this.cacheKey = cacheKeyElements.join('/');
        this.customRequestOptions = cfg.customRequestOptions || ***REMOVED***};
        this.file = cfg.file;
        this.generation = cfg.generation;
        this.kmsKeyName = cfg.kmsKeyName;
        this.metadata = cfg.metadata || ***REMOVED***};
        this.offset = cfg.offset;
        this.origin = cfg.origin;
        this.params = cfg.params || ***REMOVED***};
        this.userProject = cfg.userProject;
        this.chunkSize = cfg.chunkSize;
        this.retryOptions = cfg.retryOptions;
        if (cfg.key) ***REMOVED***
            const base64Key = Buffer.from(cfg.key).toString('base64');
            this.encryption = ***REMOVED***
                key: base64Key,
                hash: (0, crypto_1.createHash)('sha256').update(cfg.key).digest('base64'),
          ***REMOVED***;
      ***REMOVED***
        this.predefinedAcl = cfg.predefinedAcl;
        if (cfg.private)
            this.predefinedAcl = 'private';
        if (cfg.public)
            this.predefinedAcl = 'publicRead';
        const autoRetry = cfg.retryOptions.autoRetry;
        this.uriProvidedManually = !!cfg.uri;
        this.uri = cfg.uri;
        this.numBytesWritten = 0;
        this.numRetries = 0; // counter for number of retries currently executed
        if (!autoRetry) ***REMOVED***
            cfg.retryOptions.maxRetries = 0;
      ***REMOVED***
        this.timeOfFirstRequest = Date.now();
        const contentLength = cfg.metadata
            ? Number(cfg.metadata.contentLength)
            : NaN;
        this.contentLength = isNaN(contentLength) ? '*' : contentLength;
        this.once('writing', () => ***REMOVED***
            if (this.uri) ***REMOVED***
                this.continueUploading();
          ***REMOVED***
            else ***REMOVED***
                this.createURI(err => ***REMOVED***
                    if (err) ***REMOVED***
                        return this.destroy(err);
                  ***REMOVED***
                    this.startUploading();
                    return;
              ***REMOVED***);
          ***REMOVED***
      ***REMOVED***);
  ***REMOVED***
    /**
     * Prevent 'finish' event until the upload has succeeded.
     *
     * @param fireFinishEvent The finish callback
     */
    _final(fireFinishEvent = () => ***REMOVED*** }) ***REMOVED***
        this.upstreamEnded = true;
        this.once('uploadFinished', fireFinishEvent);
        process.nextTick(() => ***REMOVED***
            this.emit('upstreamFinished');
            // it's possible `_write` may not be called - namely for empty object uploads
            this.emit('writing');
      ***REMOVED***);
  ***REMOVED***
    /**
     * Handles incoming data from upstream
     *
     * @param chunk The chunk to append to the buffer
     * @param encoding The encoding of the chunk
     * @param readCallback A callback for when the buffer has been read downstream
     */
    _write(chunk, encoding, readCallback = () => ***REMOVED*** }) ***REMOVED***
        // Backwards-compatible event
        this.emit('writing');
        this.upstreamChunkBuffer = Buffer.concat([
            this.upstreamChunkBuffer,
            typeof chunk === 'string' ? Buffer.from(chunk, encoding) : chunk,
        ]);
        this.chunkBufferEncoding = encoding;
        this.once('readFromChunkBuffer', readCallback);
        process.nextTick(() => this.emit('wroteToChunkBuffer'));
  ***REMOVED***
    /**
     * Prepends data back to the upstream chunk buffer.
     *
     * @param chunk The data to prepend
     */
    unshiftChunkBuffer(chunk) ***REMOVED***
        this.upstreamChunkBuffer = Buffer.concat([chunk, this.upstreamChunkBuffer]);
  ***REMOVED***
    /**
     * Retrieves data from upstream's buffer.
     *
     * @param limit The maximum amount to return from the buffer.
     * @returns The data requested.
     */
    pullFromChunkBuffer(limit) ***REMOVED***
        const chunk = this.upstreamChunkBuffer.slice(0, limit);
        this.upstreamChunkBuffer = this.upstreamChunkBuffer.slice(limit);
        // notify upstream we've read from the buffer so it can potentially
        // send more data down.
        process.nextTick(() => this.emit('readFromChunkBuffer'));
        return chunk;
  ***REMOVED***
    /**
     * A handler for determining if data is ready to be read from upstream.
     *
     * @returns If there will be more chunks to read in the future
     */
    async waitForNextChunk() ***REMOVED***
        const willBeMoreChunks = await new Promise(resolve => ***REMOVED***
            // There's data available - it should be digested
            if (this.upstreamChunkBuffer.byteLength) ***REMOVED***
                return resolve(true);
          ***REMOVED***
            // The upstream writable ended, we shouldn't expect any more data.
            if (this.upstreamEnded) ***REMOVED***
                return resolve(false);
          ***REMOVED***
            // Nothing immediate seems to be determined. We need to prepare some
            // listeners to determine next steps...
            const wroteToChunkBufferCallback = () => ***REMOVED***
                removeListeners();
                return resolve(true);
          ***REMOVED***;
            const upstreamFinishedCallback = () => ***REMOVED***
                removeListeners();
                // this should be the last chunk, if there's anything there
                if (this.upstreamChunkBuffer.length)
                    return resolve(true);
                return resolve(false);
          ***REMOVED***;
            // Remove listeners when we're ready to callback.
            const removeListeners = () => ***REMOVED***
                this.removeListener('wroteToChunkBuffer', wroteToChunkBufferCallback);
                this.removeListener('upstreamFinished', upstreamFinishedCallback);
          ***REMOVED***;
            // If there's data recently written it should be digested
            this.once('wroteToChunkBuffer', wroteToChunkBufferCallback);
            // If the upstream finishes let's see if there's anything to grab
            this.once('upstreamFinished', upstreamFinishedCallback);
      ***REMOVED***);
        return willBeMoreChunks;
  ***REMOVED***
    /**
     * Reads data from upstream up to the provided `limit`.
     * Ends when the limit has reached or no data is expected to be pushed from upstream.
     *
     * @param limit The most amount of data this iterator should return. `Infinity` by default.
     * @param oneChunkMode Determines if one, exhaustive chunk is yielded for the iterator
     */
    async *upstreamIterator(limit = Infinity, oneChunkMode) ***REMOVED***
        let completeChunk = Buffer.alloc(0);
        // read from upstream chunk buffer
        while (limit && (await this.waitForNextChunk())) ***REMOVED***
            // read until end or limit has been reached
            const chunk = this.pullFromChunkBuffer(limit);
            limit -= chunk.byteLength;
            if (oneChunkMode) ***REMOVED***
                // return 1 chunk at the end of iteration
                completeChunk = Buffer.concat([completeChunk, chunk]);
          ***REMOVED***
            else ***REMOVED***
                // return many chunks throughout iteration
                yield ***REMOVED***
                    chunk,
                    encoding: this.chunkBufferEncoding,
              ***REMOVED***;
          ***REMOVED***
      ***REMOVED***
        if (oneChunkMode) ***REMOVED***
            yield ***REMOVED***
                chunk: completeChunk,
                encoding: this.chunkBufferEncoding,
          ***REMOVED***;
      ***REMOVED***
  ***REMOVED***
    createURI(callback) ***REMOVED***
        if (!callback) ***REMOVED***
            return this.createURIAsync();
      ***REMOVED***
        this.createURIAsync().then(r => callback(null, r), callback);
  ***REMOVED***
    async createURIAsync() ***REMOVED***
        const metadata = ***REMOVED*** ...this.metadata };
        const headers = ***REMOVED***};
        // Delete content length and content type from metadata if they exist.
        // These are headers and should not be sent as part of the metadata.
        if (metadata.contentLength) ***REMOVED***
            headers['X-Upload-Content-Length'] = metadata.contentLength.toString();
            delete metadata.contentLength;
      ***REMOVED***
        if (metadata.contentType) ***REMOVED***
            headers['X-Upload-Content-Type'] = metadata.contentType;
            delete metadata.contentType;
      ***REMOVED***
        // Check if headers already exist before creating new ones
        const reqOpts = ***REMOVED***
            method: 'POST',
            url: [this.baseURI, this.bucket, 'o'].join('/'),
            params: Object.assign(***REMOVED***
                name: this.file,
                uploadType: 'resumable',
          ***REMOVED***, this.params),
            data: metadata,
            headers: ***REMOVED***
                'x-goog-api-client': `gl-node/$***REMOVED***process.versions.node} gccl/$***REMOVED***packageJson.version} gccl-invocation-id/$***REMOVED***this.currentInvocationId.uri}`,
                ...headers,
          ***REMOVED***,
      ***REMOVED***;
        if (metadata.contentLength) ***REMOVED***
            reqOpts.headers['X-Upload-Content-Length'] =
                metadata.contentLength.toString();
      ***REMOVED***
        if (metadata.contentType) ***REMOVED***
            reqOpts.headers['X-Upload-Content-Type'] = metadata.contentType;
      ***REMOVED***
        if (typeof this.generation !== 'undefined') ***REMOVED***
            reqOpts.params.ifGenerationMatch = this.generation;
      ***REMOVED***
        if (this.kmsKeyName) ***REMOVED***
            reqOpts.params.kmsKeyName = this.kmsKeyName;
      ***REMOVED***
        if (this.predefinedAcl) ***REMOVED***
            reqOpts.params.predefinedAcl = this.predefinedAcl;
      ***REMOVED***
        if (this.origin) ***REMOVED***
            reqOpts.headers.Origin = this.origin;
      ***REMOVED***
        const uri = await retry(async (bail) => ***REMOVED***
            var _a, _b, _c;
            try ***REMOVED***
                const res = await this.makeRequest(reqOpts);
                // We have successfully got a URI we can now create a new invocation id
                this.currentInvocationId.uri = uuid.v4();
                return res.headers.location;
          ***REMOVED***
            catch (err) ***REMOVED***
                const e = err;
                const apiError = ***REMOVED***
                    code: (_a = e.response) === null || _a === void 0 ? void 0 : _a.status,
                    name: (_b = e.response) === null || _b === void 0 ? void 0 : _b.statusText,
                    message: (_c = e.response) === null || _c === void 0 ? void 0 : _c.statusText,
                    errors: [
                        ***REMOVED***
                            reason: e.code,
                      ***REMOVED***,
                    ],
              ***REMOVED***;
                if (this.retryOptions.maxRetries > 0 &&
                    this.retryOptions.retryableErrorFn(apiError)) ***REMOVED***
                    throw e;
              ***REMOVED***
                else ***REMOVED***
                    return bail(e);
              ***REMOVED***
          ***REMOVED***
      ***REMOVED***, ***REMOVED***
            retries: this.retryOptions.maxRetries,
            factor: this.retryOptions.retryDelayMultiplier,
            maxTimeout: this.retryOptions.maxRetryDelay * 1000,
            maxRetryTime: this.retryOptions.totalTimeout * 1000, //convert to milliseconds
      ***REMOVED***);
        this.uri = uri;
        this.offset = 0;
        return uri;
  ***REMOVED***
    async continueUploading() ***REMOVED***
        if (typeof this.offset === 'number') ***REMOVED***
            this.startUploading();
            return;
      ***REMOVED***
        await this.getAndSetOffset();
        this.startUploading();
  ***REMOVED***
    async startUploading() ***REMOVED***
        const multiChunkMode = !!this.chunkSize;
        let responseReceived = false;
        this.numChunksReadInRequest = 0;
        if (!this.offset) ***REMOVED***
            this.offset = 0;
      ***REMOVED***
        // Check if the offset (server) is too far behind the current stream
        if (this.offset < this.numBytesWritten) ***REMOVED***
            const delta = this.numBytesWritten - this.offset;
            const message = `The offset is lower than the number of bytes written. The server has $***REMOVED***this.offset} bytes and while $***REMOVED***this.numBytesWritten} bytes has been uploaded - thus $***REMOVED***delta} bytes are missing. Stopping as this could result in data loss. Initiate a new upload to continue.`;
            this.emit('error', new RangeError(message));
            return;
      ***REMOVED***
        // Check if we should 'fast-forward' to the relevant data to upload
        if (this.numBytesWritten < this.offset) ***REMOVED***
            // 'fast-forward' to the byte where we need to upload.
            // only push data from the byte after the one we left off on
            const fastForwardBytes = this.offset - this.numBytesWritten;
            for await (const _chunk of this.upstreamIterator(fastForwardBytes)) ***REMOVED***
                _chunk; // discard the data up until the point we want
          ***REMOVED***
            this.numBytesWritten = this.offset;
      ***REMOVED***
        let expectedUploadSize = undefined;
        // Set `expectedUploadSize` to `contentLength - this.numBytesWritten`, if available
        if (typeof this.contentLength === 'number') ***REMOVED***
            expectedUploadSize = this.contentLength - this.numBytesWritten;
      ***REMOVED***
        // `expectedUploadSize` should be no more than the `chunkSize`.
        // It's possible this is the last chunk request for a multiple
        // chunk upload, thus smaller than the chunk size.
        if (this.chunkSize) ***REMOVED***
            expectedUploadSize = expectedUploadSize
                ? Math.min(this.chunkSize, expectedUploadSize)
                : this.chunkSize;
      ***REMOVED***
        // A queue for the upstream data
        const upstreamQueue = this.upstreamIterator(expectedUploadSize, multiChunkMode // multi-chunk mode should return 1 chunk per request
        );
        // The primary read stream for this request. This stream retrieves no more
        // than the exact requested amount from upstream.
        const requestStream = new stream_1.Readable(***REMOVED***
            read: async () => ***REMOVED***
                // Don't attempt to retrieve data upstream if we already have a response
                if (responseReceived)
                    requestStream.push(null);
                const result = await upstreamQueue.next();
                if (result.value) ***REMOVED***
                    this.numChunksReadInRequest++;
                    this.lastChunkSent = result.value.chunk;
                    this.numBytesWritten += result.value.chunk.byteLength;
                    this.emit('progress', ***REMOVED***
                        bytesWritten: this.numBytesWritten,
                        contentLength: this.contentLength,
                  ***REMOVED***);
                    requestStream.push(result.value.chunk, result.value.encoding);
              ***REMOVED***
                if (result.done) ***REMOVED***
                    requestStream.push(null);
              ***REMOVED***
          ***REMOVED***,
      ***REMOVED***);
        const headers = ***REMOVED***
            'x-goog-api-client': `gl-node/$***REMOVED***process.versions.node} gccl/$***REMOVED***packageJson.version} gccl-invocation-id/$***REMOVED***this.currentInvocationId.chunk}`,
      ***REMOVED***;
        // If using multiple chunk upload, set appropriate header
        if (multiChunkMode) ***REMOVED***
            // We need to know how much data is available upstream to set the `Content-Range` header.
            const oneChunkIterator = this.upstreamIterator(expectedUploadSize, true);
            const ***REMOVED*** value } = await oneChunkIterator.next();
            const bytesToUpload = value.chunk.byteLength;
            // Important: we want to know if the upstream has ended and the queue is empty before
            // unshifting data back into the queue. This way we will know if this is the last request or not.
            const isLastChunkOfUpload = !(await this.waitForNextChunk());
            // Important: put the data back in the queue for the actual upload iterator
            this.unshiftChunkBuffer(value.chunk);
            let totalObjectSize = this.contentLength;
            if (typeof this.contentLength !== 'number' && isLastChunkOfUpload) ***REMOVED***
                // Let's let the server know this is the last chunk since
                // we didn't know the content-length beforehand.
                totalObjectSize = bytesToUpload + this.numBytesWritten;
          ***REMOVED***
            // `- 1` as the ending byte is inclusive in the request.
            const endingByte = bytesToUpload + this.numBytesWritten - 1;
            // `Content-Length` for multiple chunk uploads is the size of the chunk,
            // not the overall object
            headers['Content-Length'] = bytesToUpload;
            headers['Content-Range'] = `bytes $***REMOVED***this.offset}-$***REMOVED***endingByte}/$***REMOVED***totalObjectSize}`;
      ***REMOVED***
        else ***REMOVED***
            headers['Content-Range'] = `bytes $***REMOVED***this.offset}-*/$***REMOVED***this.contentLength}`;
      ***REMOVED***
        const reqOpts = ***REMOVED***
            method: 'PUT',
            url: this.uri,
            headers,
            body: requestStream,
      ***REMOVED***;
        try ***REMOVED***
            const resp = await this.makeRequestStream(reqOpts);
            if (resp) ***REMOVED***
                responseReceived = true;
                this.responseHandler(resp);
          ***REMOVED***
      ***REMOVED***
        catch (e) ***REMOVED***
            const err = e;
            if (this.retryOptions.retryableErrorFn(err)) ***REMOVED***
                this.attemptDelayedRetry(***REMOVED***
                    status: NaN,
                    data: err,
              ***REMOVED***);
                return;
          ***REMOVED***
            this.destroy(err);
      ***REMOVED***
  ***REMOVED***
    // Process the API response to look for errors that came in
    // the response body.
    responseHandler(resp) ***REMOVED***
        if (resp.data.error) ***REMOVED***
            this.destroy(resp.data.error);
            return;
      ***REMOVED***
        // At this point we can safely create a new id for the chunk
        this.currentInvocationId.chunk = uuid.v4();
        const shouldContinueWithNextMultiChunkRequest = this.chunkSize &&
            resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE &&
            resp.headers.range;
        if (shouldContinueWithNextMultiChunkRequest) ***REMOVED***
            // Use the upper value in this header to determine where to start the next chunk.
            // We should not assume that the server received all bytes sent in the request.
            // https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload
            const range = resp.headers.range;
            this.offset = Number(range.split('-')[1]) + 1;
            // We should not assume that the server received all bytes sent in the request.
            // - https://cloud.google.com/storage/docs/performing-resumable-uploads#chunked-upload
            const missingBytes = this.numBytesWritten - this.offset;
            if (missingBytes) ***REMOVED***
                const dataToPrependForResending = this.lastChunkSent.slice(-missingBytes);
                // As multi-chunk uploads send one chunk per request and pulls one
                // chunk into the pipeline, prepending the missing bytes back should
                // be fine for the next request.
                this.unshiftChunkBuffer(dataToPrependForResending);
                this.numBytesWritten -= missingBytes;
                this.lastChunkSent = Buffer.alloc(0);
          ***REMOVED***
            // continue uploading next chunk
            this.continueUploading();
      ***REMOVED***
        else if (!this.isSuccessfulResponse(resp.status)) ***REMOVED***
            const err = new Error('Upload failed');
            err.code = resp.status;
            err.name = 'Upload failed';
            if (resp === null || resp === void 0 ? void 0 : resp.data) ***REMOVED***
                err.errors = [resp === null || resp === void 0 ? void 0 : resp.data];
          ***REMOVED***
            this.destroy(err);
      ***REMOVED***
        else ***REMOVED***
            // remove the last chunk sent to free memory
            this.lastChunkSent = Buffer.alloc(0);
            if (resp && resp.data) ***REMOVED***
                resp.data.size = Number(resp.data.size);
          ***REMOVED***
            this.emit('metadata', resp.data);
            // Allow the object (Upload) to continue naturally so the user's
            // "finish" event fires.
            this.emit('uploadFinished');
      ***REMOVED***
  ***REMOVED***
    async getAndSetOffset() ***REMOVED***
        const opts = ***REMOVED***
            method: 'PUT',
            url: this.uri,
            headers: ***REMOVED***
                'Content-Length': 0,
                'Content-Range': 'bytes */*',
                'x-goog-api-client': `gl-node/$***REMOVED***process.versions.node} gccl/$***REMOVED***packageJson.version} gccl-invocation-id/$***REMOVED***this.currentInvocationId.offset}`,
          ***REMOVED***,
      ***REMOVED***;
        try ***REMOVED***
            const resp = await this.makeRequest(opts);
            // Successfully got the offset we can now create a new offset invocation id
            this.currentInvocationId.offset = uuid.v4();
            if (resp.status === RESUMABLE_INCOMPLETE_STATUS_CODE) ***REMOVED***
                if (resp.headers.range) ***REMOVED***
                    const range = resp.headers.range;
                    this.offset = Number(range.split('-')[1]) + 1;
                    return;
              ***REMOVED***
          ***REMOVED***
            this.offset = 0;
      ***REMOVED***
        catch (e) ***REMOVED***
            const err = e;
            if (this.retryOptions.retryableErrorFn(err)) ***REMOVED***
                this.attemptDelayedRetry(***REMOVED***
                    status: NaN,
                    data: err,
              ***REMOVED***);
                return;
          ***REMOVED***
            this.destroy(err);
      ***REMOVED***
  ***REMOVED***
    async makeRequest(reqOpts) ***REMOVED***
        if (this.encryption) ***REMOVED***
            reqOpts.headers = reqOpts.headers || ***REMOVED***};
            reqOpts.headers['x-goog-encryption-algorithm'] = 'AES256';
            reqOpts.headers['x-goog-encryption-key'] = this.encryption.key.toString();
            reqOpts.headers['x-goog-encryption-key-sha256'] =
                this.encryption.hash.toString();
      ***REMOVED***
        if (this.userProject) ***REMOVED***
            reqOpts.params = reqOpts.params || ***REMOVED***};
            reqOpts.params.userProject = this.userProject;
      ***REMOVED***
        // Let gaxios know we will handle a 308 error code ourselves.
        reqOpts.validateStatus = (status) => ***REMOVED***
            return (this.isSuccessfulResponse(status) ||
                status === RESUMABLE_INCOMPLETE_STATUS_CODE);
      ***REMOVED***;
        const combinedReqOpts = extend(true, ***REMOVED***}, this.customRequestOptions, reqOpts);
        const res = await this.authClient.request(combinedReqOpts);
        if (res.data && res.data.error) ***REMOVED***
            throw res.data.error;
      ***REMOVED***
        return res;
  ***REMOVED***
    async makeRequestStream(reqOpts) ***REMOVED***
        const controller = new abort_controller_1.default();
        const errorCallback = () => controller.abort();
        this.once('error', errorCallback);
        if (this.userProject) ***REMOVED***
            reqOpts.params = reqOpts.params || ***REMOVED***};
            reqOpts.params.userProject = this.userProject;
      ***REMOVED***
        reqOpts.signal = controller.signal;
        reqOpts.validateStatus = () => true;
        const combinedReqOpts = extend(true, ***REMOVED***}, this.customRequestOptions, reqOpts);
        const res = await this.authClient.request(combinedReqOpts);
        const successfulRequest = this.onResponse(res);
        this.removeListener('error', errorCallback);
        return successfulRequest ? res : null;
  ***REMOVED***
    /**
     * @return ***REMOVED***bool} is the request good?
     */
    onResponse(resp) ***REMOVED***
        if (resp.status !== 200 &&
            this.retryOptions.retryableErrorFn(***REMOVED***
                code: resp.status,
                message: resp.statusText,
                name: resp.statusText,
          ***REMOVED***)) ***REMOVED***
            this.attemptDelayedRetry(resp);
            return false;
      ***REMOVED***
        this.emit('response', resp);
        return true;
  ***REMOVED***
    /**
     * @param resp GaxiosResponse object from previous attempt
     */
    attemptDelayedRetry(resp) ***REMOVED***
        if (this.numRetries < this.retryOptions.maxRetries) ***REMOVED***
            if (resp.status === NOT_FOUND_STATUS_CODE &&
                this.numChunksReadInRequest === 0) ***REMOVED***
                this.startUploading();
          ***REMOVED***
            else ***REMOVED***
                const retryDelay = this.getRetryDelay();
                if (retryDelay <= 0) ***REMOVED***
                    this.destroy(new Error(`Retry total time limit exceeded - $***REMOVED***resp.data}`));
                    return;
              ***REMOVED***
                // Unshift the most recent chunk back in case it's needed for the next
                // request.
                this.numBytesWritten -= this.lastChunkSent.byteLength;
                this.unshiftChunkBuffer(this.lastChunkSent);
                this.lastChunkSent = Buffer.alloc(0);
                // We don't know how much data has been received by the server.
                // `continueUploading` will recheck the offset via `getAndSetOffset`.
                // If `offset` < `numberBytesReceived` then we will raise a RangeError
                // as we've streamed too much data that has been missed - this should
                // not be the case for multi-chunk uploads as `lastChunkSent` is the
                // body of the entire request.
                this.offset = undefined;
                setTimeout(this.continueUploading.bind(this), retryDelay);
          ***REMOVED***
            this.numRetries++;
      ***REMOVED***
        else ***REMOVED***
            this.destroy(new Error('Retry limit exceeded - ' + resp.data));
      ***REMOVED***
  ***REMOVED***
    /**
     * @returns ***REMOVED***number} the amount of time to wait before retrying the request
     */
    getRetryDelay() ***REMOVED***
        const randomMs = Math.round(Math.random() * 1000);
        const waitTime = Math.pow(this.retryOptions.retryDelayMultiplier, this.numRetries) *
            1000 +
            randomMs;
        const maxAllowableDelayMs = this.retryOptions.totalTimeout * 1000 -
            (Date.now() - this.timeOfFirstRequest);
        const maxRetryDelayMs = this.retryOptions.maxRetryDelay * 1000;
        return Math.min(waitTime, maxRetryDelayMs, maxAllowableDelayMs);
  ***REMOVED***
    /*
     * Prepare user-defined API endpoint for compatibility with our API.
     */
    sanitizeEndpoint(url) ***REMOVED***
        if (!exports.PROTOCOL_REGEX.test(url)) ***REMOVED***
            url = `https://$***REMOVED***url}`;
      ***REMOVED***
        return url.replace(/\/+$/, ''); // Remove trailing slashes
  ***REMOVED***
    /**
     * Check if a given status code is 2xx
     *
     * @param status The status code to check
     * @returns if the status is 2xx
     */
    isSuccessfulResponse(status) ***REMOVED***
        return status >= 200 && status < 300;
  ***REMOVED***
}
exports.Upload = Upload;
function upload(cfg) ***REMOVED***
    return new Upload(cfg);
}
exports.upload = upload;
function createURI(cfg, callback) ***REMOVED***
    const up = new Upload(cfg);
    if (!callback) ***REMOVED***
        return up.createURI();
  ***REMOVED***
    up.createURI().then(r => callback(null, r), callback);
}
exports.createURI = createURI;
//# sourceMappingURL=resumable-upload.js.map