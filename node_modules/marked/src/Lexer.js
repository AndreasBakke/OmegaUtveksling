import ***REMOVED*** Tokenizer } from './Tokenizer.js';
import ***REMOVED*** defaults } from './defaults.js';
import ***REMOVED*** block, inline } from './rules.js';
import ***REMOVED*** repeatString } from './helpers.js';

/**
 * smartypants text replacement
 * @param ***REMOVED***string} text
 */
function smartypants(text) ***REMOVED***
  return text
    // em-dashes
    .replace(/---/g, '\u2014')
    // en-dashes
    .replace(/--/g, '\u2013')
    // opening singles
    .replace(/(^|[-\u2014/(\[***REMOVED***"\s])'/g, '$1\u2018')
    // closing singles & apostrophes
    .replace(/'/g, '\u2019')
    // opening doubles
    .replace(/(^|[-\u2014/(\[***REMOVED***\u2018\s])"/g, '$1\u201c')
    // closing doubles
    .replace(/"/g, '\u201d')
    // ellipses
    .replace(/\.***REMOVED***3}/g, '\u2026');
}

/**
 * mangle email addresses
 * @param ***REMOVED***string} text
 */
function mangle(text) ***REMOVED***
  let out = '',
    i,
    ch;

  const l = text.length;
  for (i = 0; i < l; i++) ***REMOVED***
    ch = text.charCodeAt(i);
    if (Math.random() > 0.5) ***REMOVED***
      ch = 'x' + ch.toString(16);
  ***REMOVED***
    out += '&#' + ch + ';';
***REMOVED***

  return out;
}

/**
 * Block Lexer
 */
export class Lexer ***REMOVED***
  constructor(options) ***REMOVED***
    this.tokens = [];
    this.tokens.links = Object.create(null);
    this.options = options || defaults;
    this.options.tokenizer = this.options.tokenizer || new Tokenizer();
    this.tokenizer = this.options.tokenizer;
    this.tokenizer.options = this.options;
    this.tokenizer.lexer = this;
    this.inlineQueue = [];
    this.state = ***REMOVED***
      inLink: false,
      inRawBlock: false,
      top: true
  ***REMOVED***;

    const rules = ***REMOVED***
      block: block.normal,
      inline: inline.normal
  ***REMOVED***;

    if (this.options.pedantic) ***REMOVED***
      rules.block = block.pedantic;
      rules.inline = inline.pedantic;
  ***REMOVED*** else if (this.options.gfm) ***REMOVED***
      rules.block = block.gfm;
      if (this.options.breaks) ***REMOVED***
        rules.inline = inline.breaks;
    ***REMOVED*** else ***REMOVED***
        rules.inline = inline.gfm;
    ***REMOVED***
  ***REMOVED***
    this.tokenizer.rules = rules;
***REMOVED***

  /**
   * Expose Rules
   */
  static get rules() ***REMOVED***
    return ***REMOVED***
      block,
      inline
  ***REMOVED***;
***REMOVED***

  /**
   * Static Lex Method
   */
  static lex(src, options) ***REMOVED***
    const lexer = new Lexer(options);
    return lexer.lex(src);
***REMOVED***

  /**
   * Static Lex Inline Method
   */
  static lexInline(src, options) ***REMOVED***
    const lexer = new Lexer(options);
    return lexer.inlineTokens(src);
***REMOVED***

  /**
   * Preprocessing
   */
  lex(src) ***REMOVED***
    src = src
      .replace(/\r\n|\r/g, '\n');

    this.blockTokens(src, this.tokens);

    let next;
    while (next = this.inlineQueue.shift()) ***REMOVED***
      this.inlineTokens(next.src, next.tokens);
  ***REMOVED***

    return this.tokens;
***REMOVED***

  /**
   * Lexing
   */
  blockTokens(src, tokens = []) ***REMOVED***
    if (this.options.pedantic) ***REMOVED***
      src = src.replace(/\t/g, '    ').replace(/^ +$/gm, '');
  ***REMOVED*** else ***REMOVED***
      src = src.replace(/^( *)(\t+)/gm, (_, leading, tabs) => ***REMOVED***
        return leading + '    '.repeat(tabs.length);
    ***REMOVED***);
  ***REMOVED***

    let token, lastToken, cutSrc, lastParagraphClipped;

    while (src) ***REMOVED***
      if (this.options.extensions
        && this.options.extensions.block
        && this.options.extensions.block.some((extTokenizer) => ***REMOVED***
          if (token = extTokenizer.call(***REMOVED*** lexer: this }, src, tokens)) ***REMOVED***
            src = src.substring(token.raw.length);
            tokens.push(token);
            return true;
        ***REMOVED***
          return false;
      ***REMOVED***)) ***REMOVED***
        continue;
    ***REMOVED***

      // newline
      if (token = this.tokenizer.space(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        if (token.raw.length === 1 && tokens.length > 0) ***REMOVED***
          // if there's a single \n as a spacer, it's terminating the last line,
          // so move it there so that we don't get unecessary paragraph tags
          tokens[tokens.length - 1].raw += '\n';
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      // code
      if (token = this.tokenizer.code(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        lastToken = tokens[tokens.length - 1];
        // An indented code block cannot interrupt a paragraph.
        if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) ***REMOVED***
          lastToken.raw += '\n' + token.raw;
          lastToken.text += '\n' + token.text;
          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      // fences
      if (token = this.tokenizer.fences(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // heading
      if (token = this.tokenizer.heading(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // hr
      if (token = this.tokenizer.hr(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // blockquote
      if (token = this.tokenizer.blockquote(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // list
      if (token = this.tokenizer.list(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // html
      if (token = this.tokenizer.html(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // def
      if (token = this.tokenizer.def(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        lastToken = tokens[tokens.length - 1];
        if (lastToken && (lastToken.type === 'paragraph' || lastToken.type === 'text')) ***REMOVED***
          lastToken.raw += '\n' + token.raw;
          lastToken.text += '\n' + token.raw;
          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;
      ***REMOVED*** else if (!this.tokens.links[token.tag]) ***REMOVED***
          this.tokens.links[token.tag] = ***REMOVED***
            href: token.href,
            title: token.title
        ***REMOVED***;
      ***REMOVED***
        continue;
    ***REMOVED***

      // table (gfm)
      if (token = this.tokenizer.table(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // lheading
      if (token = this.tokenizer.lheading(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // top-level paragraph
      // prevent paragraph consuming extensions by clipping 'src' to extension start
      cutSrc = src;
      if (this.options.extensions && this.options.extensions.startBlock) ***REMOVED***
        let startIndex = Infinity;
        const tempSrc = src.slice(1);
        let tempStart;
        this.options.extensions.startBlock.forEach(function(getStartIndex) ***REMOVED***
          tempStart = getStartIndex.call(***REMOVED*** lexer: this }, tempSrc);
          if (typeof tempStart === 'number' && tempStart >= 0) ***REMOVED*** startIndex = Math.min(startIndex, tempStart); }
      ***REMOVED***);
        if (startIndex < Infinity && startIndex >= 0) ***REMOVED***
          cutSrc = src.substring(0, startIndex + 1);
      ***REMOVED***
    ***REMOVED***
      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) ***REMOVED***
        lastToken = tokens[tokens.length - 1];
        if (lastParagraphClipped && lastToken.type === 'paragraph') ***REMOVED***
          lastToken.raw += '\n' + token.raw;
          lastToken.text += '\n' + token.text;
          this.inlineQueue.pop();
          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        lastParagraphClipped = (cutSrc.length !== src.length);
        src = src.substring(token.raw.length);
        continue;
    ***REMOVED***

      // text
      if (token = this.tokenizer.text(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        lastToken = tokens[tokens.length - 1];
        if (lastToken && lastToken.type === 'text') ***REMOVED***
          lastToken.raw += '\n' + token.raw;
          lastToken.text += '\n' + token.text;
          this.inlineQueue.pop();
          this.inlineQueue[this.inlineQueue.length - 1].src = lastToken.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      if (src) ***REMOVED***
        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);
        if (this.options.silent) ***REMOVED***
          console.error(errMsg);
          break;
      ***REMOVED*** else ***REMOVED***
          throw new Error(errMsg);
      ***REMOVED***
    ***REMOVED***
  ***REMOVED***

    this.state.top = true;
    return tokens;
***REMOVED***

  inline(src, tokens = []) ***REMOVED***
    this.inlineQueue.push(***REMOVED*** src, tokens });
    return tokens;
***REMOVED***

  /**
   * Lexing/Compiling
   */
  inlineTokens(src, tokens = []) ***REMOVED***
    let token, lastToken, cutSrc;

    // String with links masked to avoid interference with em and strong
    let maskedSrc = src;
    let match;
    let keepPrevChar, prevChar;

    // Mask out reflinks
    if (this.tokens.links) ***REMOVED***
      const links = Object.keys(this.tokens.links);
      if (links.length > 0) ***REMOVED***
        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) ***REMOVED***
          if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) ***REMOVED***
            maskedSrc = maskedSrc.slice(0, match.index) + '[' + repeatString('a', match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);
        ***REMOVED***
      ***REMOVED***
    ***REMOVED***
  ***REMOVED***
    // Mask out other blocks
    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) ***REMOVED***
      maskedSrc = maskedSrc.slice(0, match.index) + '[' + repeatString('a', match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);
  ***REMOVED***

    // Mask out escaped em & strong delimiters
    while ((match = this.tokenizer.rules.inline.escapedEmSt.exec(maskedSrc)) != null) ***REMOVED***
      maskedSrc = maskedSrc.slice(0, match.index + match[0].length - 2) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.escapedEmSt.lastIndex);
      this.tokenizer.rules.inline.escapedEmSt.lastIndex--;
  ***REMOVED***

    while (src) ***REMOVED***
      if (!keepPrevChar) ***REMOVED***
        prevChar = '';
    ***REMOVED***
      keepPrevChar = false;

      // extensions
      if (this.options.extensions
        && this.options.extensions.inline
        && this.options.extensions.inline.some((extTokenizer) => ***REMOVED***
          if (token = extTokenizer.call(***REMOVED*** lexer: this }, src, tokens)) ***REMOVED***
            src = src.substring(token.raw.length);
            tokens.push(token);
            return true;
        ***REMOVED***
          return false;
      ***REMOVED***)) ***REMOVED***
        continue;
    ***REMOVED***

      // escape
      if (token = this.tokenizer.escape(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // tag
      if (token = this.tokenizer.tag(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        lastToken = tokens[tokens.length - 1];
        if (lastToken && token.type === 'text' && lastToken.type === 'text') ***REMOVED***
          lastToken.raw += token.raw;
          lastToken.text += token.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      // link
      if (token = this.tokenizer.link(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // reflink, nolink
      if (token = this.tokenizer.reflink(src, this.tokens.links)) ***REMOVED***
        src = src.substring(token.raw.length);
        lastToken = tokens[tokens.length - 1];
        if (lastToken && token.type === 'text' && lastToken.type === 'text') ***REMOVED***
          lastToken.raw += token.raw;
          lastToken.text += token.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      // em & strong
      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // code
      if (token = this.tokenizer.codespan(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // br
      if (token = this.tokenizer.br(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // del (gfm)
      if (token = this.tokenizer.del(src)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // autolink
      if (token = this.tokenizer.autolink(src, mangle)) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // url (gfm)
      if (!this.state.inLink && (token = this.tokenizer.url(src, mangle))) ***REMOVED***
        src = src.substring(token.raw.length);
        tokens.push(token);
        continue;
    ***REMOVED***

      // text
      // prevent inlineText consuming extensions by clipping 'src' to extension start
      cutSrc = src;
      if (this.options.extensions && this.options.extensions.startInline) ***REMOVED***
        let startIndex = Infinity;
        const tempSrc = src.slice(1);
        let tempStart;
        this.options.extensions.startInline.forEach(function(getStartIndex) ***REMOVED***
          tempStart = getStartIndex.call(***REMOVED*** lexer: this }, tempSrc);
          if (typeof tempStart === 'number' && tempStart >= 0) ***REMOVED*** startIndex = Math.min(startIndex, tempStart); }
      ***REMOVED***);
        if (startIndex < Infinity && startIndex >= 0) ***REMOVED***
          cutSrc = src.substring(0, startIndex + 1);
      ***REMOVED***
    ***REMOVED***
      if (token = this.tokenizer.inlineText(cutSrc, smartypants)) ***REMOVED***
        src = src.substring(token.raw.length);
        if (token.raw.slice(-1) !== '_') ***REMOVED*** // Track prevChar before string of ____ started
          prevChar = token.raw.slice(-1);
      ***REMOVED***
        keepPrevChar = true;
        lastToken = tokens[tokens.length - 1];
        if (lastToken && lastToken.type === 'text') ***REMOVED***
          lastToken.raw += token.raw;
          lastToken.text += token.text;
      ***REMOVED*** else ***REMOVED***
          tokens.push(token);
      ***REMOVED***
        continue;
    ***REMOVED***

      if (src) ***REMOVED***
        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);
        if (this.options.silent) ***REMOVED***
          console.error(errMsg);
          break;
      ***REMOVED*** else ***REMOVED***
          throw new Error(errMsg);
      ***REMOVED***
    ***REMOVED***
  ***REMOVED***

    return tokens;
***REMOVED***
}
